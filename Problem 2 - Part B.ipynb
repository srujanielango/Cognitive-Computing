{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "config.add_section('Constants')\n",
    "config.set('Constants', 'batch_size','32')\n",
    "config.set('Constants', 'num_classes','10')\n",
    "config.set('Constants', 'epochs','100')\n",
    "config.set('Constants', 'data_augmentation','True')\n",
    "config.set('Constants', 'num_predictions','20')\n",
    "\n",
    "with open('/Spring 2018/AI/Assignment-1/configuration-base.ini', 'w') as configfile:\n",
    "    config.write(configfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "config.add_section('Constants')\n",
    "config.set('Constants', 'batch_size','64')\n",
    "config.set('Constants', 'num_classes','10')\n",
    "config.set('Constants', 'epochs','100')\n",
    "config.set('Constants', 'data_augmentation','True')\n",
    "config.set('Constants', 'num_predictions','10')\n",
    "\n",
    "with open('/Spring 2018/AI/Assignment-1/configuration-1.ini', 'w') as configfile:\n",
    "    config.write(configfile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "config.add_section('Constants')\n",
    "config.set('Constants', 'batch_size','128')\n",
    "config.set('Constants', 'num_classes','10')\n",
    "config.set('Constants', 'epochs','200')\n",
    "config.set('Constants', 'data_augmentation','True')\n",
    "config.set('Constants', 'num_predictions','20')\n",
    "\n",
    "with open('/Spring 2018/AI/Assignment-1/configuration-2.ini', 'w') as configfile:\n",
    "    config.write(configfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "config.add_section('Constants')\n",
    "config.set('Constants', 'batch_size','256')\n",
    "config.set('Constants', 'num_classes','10')\n",
    "config.set('Constants', 'epochs','100')\n",
    "config.set('Constants', 'data_augmentation','False')\n",
    "config.set('Constants', 'num_predictions','20')\n",
    "\n",
    "with open('/Spring 2018/AI/Assignment-1/configuration-3.ini', 'w') as configfile:\n",
    "    config.write(configfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading base parameters from config file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading parameters from base file test accuracy is 78%. Shows that it is a good model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 1.8493 - acc: 0.3177 - val_loss: 1.5472 - val_acc: 0.4360\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 1.5634 - acc: 0.4270 - val_loss: 1.4085 - val_acc: 0.4996\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 1.4330 - acc: 0.4839 - val_loss: 1.2489 - val_acc: 0.5619\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 1.3409 - acc: 0.5191 - val_loss: 1.1665 - val_acc: 0.5859\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 1.2721 - acc: 0.5455 - val_loss: 1.1238 - val_acc: 0.6033\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 1.2103 - acc: 0.5690 - val_loss: 1.0526 - val_acc: 0.6264\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 27s 17ms/step - loss: 1.1614 - acc: 0.5874 - val_loss: 0.9983 - val_acc: 0.6479\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 1.1118 - acc: 0.6099 - val_loss: 0.9591 - val_acc: 0.6628\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 1.0721 - acc: 0.6218 - val_loss: 0.9302 - val_acc: 0.6731\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.0423 - acc: 0.6328 - val_loss: 0.8988 - val_acc: 0.6902\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 1.0107 - acc: 0.6455 - val_loss: 0.8814 - val_acc: 0.6851\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.9845 - acc: 0.6541 - val_loss: 0.8286 - val_acc: 0.7086\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.9628 - acc: 0.6629 - val_loss: 0.8341 - val_acc: 0.7060\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.9381 - acc: 0.6732 - val_loss: 0.8859 - val_acc: 0.6909\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.9228 - acc: 0.6769 - val_loss: 0.7731 - val_acc: 0.7250\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.9069 - acc: 0.6820 - val_loss: 0.7789 - val_acc: 0.7271\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.8954 - acc: 0.6872 - val_loss: 0.7590 - val_acc: 0.7304\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.8832 - acc: 0.6941 - val_loss: 0.7333 - val_acc: 0.7450\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.8694 - acc: 0.6994 - val_loss: 0.7439 - val_acc: 0.7452\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.8613 - acc: 0.6996 - val_loss: 0.7170 - val_acc: 0.7522\n",
      "Epoch 21/100\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.8502 - acc: 0.7055 - val_loss: 0.7538 - val_acc: 0.7406\n",
      "Epoch 22/100\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.8419 - acc: 0.7118 - val_loss: 0.7017 - val_acc: 0.7549\n",
      "Epoch 23/100\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.8333 - acc: 0.7117 - val_loss: 0.7134 - val_acc: 0.7545\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.8280 - acc: 0.7156 - val_loss: 0.7474 - val_acc: 0.7446\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.8271 - acc: 0.7159 - val_loss: 0.7158 - val_acc: 0.7505\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.8226 - acc: 0.7192 - val_loss: 0.7033 - val_acc: 0.7628\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.8113 - acc: 0.7196 - val_loss: 0.6812 - val_acc: 0.7717\n",
      "Epoch 28/100\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.8056 - acc: 0.7236 - val_loss: 0.6732 - val_acc: 0.7679\n",
      "Epoch 29/100\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.8042 - acc: 0.7232 - val_loss: 0.6765 - val_acc: 0.7714\n",
      "Epoch 30/100\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.7989 - acc: 0.7256 - val_loss: 0.6712 - val_acc: 0.7758\n",
      "Epoch 31/100\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.7959 - acc: 0.7279 - val_loss: 0.6997 - val_acc: 0.7662\n",
      "Epoch 32/100\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.7970 - acc: 0.7297 - val_loss: 0.6515 - val_acc: 0.7759\n",
      "Epoch 33/100\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.7893 - acc: 0.7296 - val_loss: 0.6494 - val_acc: 0.7812\n",
      "Epoch 34/100\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 0.7822 - acc: 0.7313 - val_loss: 0.6543 - val_acc: 0.7803\n",
      "Epoch 35/100\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.7825 - acc: 0.7348 - val_loss: 0.6695 - val_acc: 0.7781\n",
      "Epoch 36/100\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.7743 - acc: 0.7375 - val_loss: 0.6384 - val_acc: 0.7822\n",
      "Epoch 37/100\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.7770 - acc: 0.7356 - val_loss: 0.6416 - val_acc: 0.7820\n",
      "Epoch 38/100\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.7715 - acc: 0.7392 - val_loss: 0.6344 - val_acc: 0.7821\n",
      "Epoch 39/100\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 0.7737 - acc: 0.7379 - val_loss: 0.6632 - val_acc: 0.7746\n",
      "Epoch 40/100\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 0.7719 - acc: 0.7391 - val_loss: 0.6426 - val_acc: 0.7829\n",
      "Epoch 41/100\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.7654 - acc: 0.7388 - val_loss: 0.6545 - val_acc: 0.7840\n",
      "Epoch 42/100\n",
      "1563/1563 [==============================] - 24s 16ms/step - loss: 0.7605 - acc: 0.7428 - val_loss: 0.6593 - val_acc: 0.7807\n",
      "Epoch 43/100\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 0.7612 - acc: 0.7423 - val_loss: 0.6611 - val_acc: 0.7784\n",
      "Epoch 44/100\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.7605 - acc: 0.7415 - val_loss: 0.6543 - val_acc: 0.7832\n",
      "Epoch 45/100\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.7582 - acc: 0.7440 - val_loss: 0.6550 - val_acc: 0.7760\n",
      "Epoch 46/100\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.7548 - acc: 0.7427 - val_loss: 0.6834 - val_acc: 0.7738\n",
      "Epoch 47/100\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.7534 - acc: 0.7446 - val_loss: 0.6380 - val_acc: 0.7884\n",
      "Epoch 48/100\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.7492 - acc: 0.7457 - val_loss: 0.6541 - val_acc: 0.7732\n",
      "Epoch 49/100\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.7468 - acc: 0.7470 - val_loss: 0.6507 - val_acc: 0.7841\n",
      "Epoch 50/100\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.7414 - acc: 0.7512 - val_loss: 0.6142 - val_acc: 0.7901\n",
      "Epoch 51/100\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.7432 - acc: 0.7473 - val_loss: 0.6428 - val_acc: 0.7897\n",
      "Epoch 52/100\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.7448 - acc: 0.7494 - val_loss: 0.6530 - val_acc: 0.7808\n",
      "Epoch 53/100\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.7441 - acc: 0.7491 - val_loss: 0.6420 - val_acc: 0.7866\n",
      "Epoch 54/100\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.7424 - acc: 0.7506 - val_loss: 0.6555 - val_acc: 0.7808\n",
      "Epoch 55/100\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.7414 - acc: 0.7504 - val_loss: 0.6299 - val_acc: 0.7920\n",
      "Epoch 56/100\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.7402 - acc: 0.7496 - val_loss: 0.6855 - val_acc: 0.7694\n",
      "Epoch 57/100\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.7385 - acc: 0.7523 - val_loss: 0.6421 - val_acc: 0.7863\n",
      "Epoch 58/100\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.7405 - acc: 0.7518 - val_loss: 0.7484 - val_acc: 0.7487\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.7405 - acc: 0.7518 - val_loss: 0.6789 - val_acc: 0.7796\n",
      "Epoch 60/100\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.7353 - acc: 0.7531 - val_loss: 0.6373 - val_acc: 0.7825\n",
      "Epoch 61/100\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.7367 - acc: 0.7535 - val_loss: 0.6238 - val_acc: 0.7945\n",
      "Epoch 62/100\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.7404 - acc: 0.7516 - val_loss: 0.6168 - val_acc: 0.7949\n",
      "Epoch 63/100\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.7391 - acc: 0.7522 - val_loss: 0.6446 - val_acc: 0.7846\n",
      "Epoch 64/100\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.7406 - acc: 0.7527 - val_loss: 0.6488 - val_acc: 0.7968\n",
      "Epoch 65/100\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.7354 - acc: 0.7540 - val_loss: 0.6188 - val_acc: 0.7953\n",
      "Epoch 66/100\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.7355 - acc: 0.7548 - val_loss: 0.6474 - val_acc: 0.7867\n",
      "Epoch 67/100\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.7398 - acc: 0.7526 - val_loss: 0.6541 - val_acc: 0.7861\n",
      "Epoch 68/100\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.7401 - acc: 0.7526 - val_loss: 0.6393 - val_acc: 0.7875\n",
      "Epoch 69/100\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.7382 - acc: 0.7538 - val_loss: 0.6425 - val_acc: 0.7884\n",
      "Epoch 70/100\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.7405 - acc: 0.7535 - val_loss: 0.6360 - val_acc: 0.7959\n",
      "Epoch 71/100\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.7371 - acc: 0.7531 - val_loss: 0.6398 - val_acc: 0.7911\n",
      "Epoch 72/100\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.7440 - acc: 0.7508 - val_loss: 0.6049 - val_acc: 0.7943\n",
      "Epoch 73/100\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.7396 - acc: 0.7540 - val_loss: 0.6508 - val_acc: 0.7919\n",
      "Epoch 74/100\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.7400 - acc: 0.7549 - val_loss: 0.6148 - val_acc: 0.7997\n",
      "Epoch 75/100\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.7443 - acc: 0.7528 - val_loss: 0.6192 - val_acc: 0.7946\n",
      "Epoch 76/100\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.7447 - acc: 0.7504 - val_loss: 0.6227 - val_acc: 0.8000\n",
      "Epoch 77/100\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.7428 - acc: 0.7544 - val_loss: 0.6177 - val_acc: 0.7975\n",
      "Epoch 78/100\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.7461 - acc: 0.7537 - val_loss: 0.6536 - val_acc: 0.7897\n",
      "Epoch 79/100\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.7515 - acc: 0.7498 - val_loss: 0.6608 - val_acc: 0.7926\n",
      "Epoch 80/100\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.7464 - acc: 0.7516 - val_loss: 0.6453 - val_acc: 0.7912\n",
      "Epoch 81/100\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.7439 - acc: 0.7526 - val_loss: 0.6410 - val_acc: 0.7856\n",
      "Epoch 82/100\n",
      "1563/1563 [==============================] - 24s 16ms/step - loss: 0.7445 - acc: 0.7539 - val_loss: 0.6326 - val_acc: 0.7937\n",
      "Epoch 83/100\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.7456 - acc: 0.7527 - val_loss: 0.6502 - val_acc: 0.7960\n",
      "Epoch 84/100\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.7532 - acc: 0.7523 - val_loss: 0.6709 - val_acc: 0.7857\n",
      "Epoch 85/100\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.7480 - acc: 0.7522 - val_loss: 0.6606 - val_acc: 0.7842\n",
      "Epoch 86/100\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.7554 - acc: 0.7488 - val_loss: 0.6049 - val_acc: 0.7987\n",
      "Epoch 87/100\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.7416 - acc: 0.7534 - val_loss: 0.6470 - val_acc: 0.7973\n",
      "Epoch 88/100\n",
      "1563/1563 [==============================] - 27s 18ms/step - loss: 0.7526 - acc: 0.7529 - val_loss: 0.6567 - val_acc: 0.7785\n",
      "Epoch 89/100\n",
      "1563/1563 [==============================] - 27s 17ms/step - loss: 0.7523 - acc: 0.7517 - val_loss: 0.6659 - val_acc: 0.7799\n",
      "Epoch 90/100\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.7481 - acc: 0.7529 - val_loss: 0.7426 - val_acc: 0.7596\n",
      "Epoch 91/100\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.7537 - acc: 0.7503 - val_loss: 0.6326 - val_acc: 0.7945\n",
      "Epoch 92/100\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.7604 - acc: 0.7495 - val_loss: 0.6118 - val_acc: 0.7950\n",
      "Epoch 93/100\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.7585 - acc: 0.7502 - val_loss: 0.6473 - val_acc: 0.7877\n",
      "Epoch 94/100\n",
      "1563/1563 [==============================] - 27s 17ms/step - loss: 0.7634 - acc: 0.7499 - val_loss: 0.6950 - val_acc: 0.7736\n",
      "Epoch 95/100\n",
      "1563/1563 [==============================] - 27s 17ms/step - loss: 0.7630 - acc: 0.7483 - val_loss: 0.7001 - val_acc: 0.7800\n",
      "Epoch 96/100\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.7623 - acc: 0.7509 - val_loss: 0.7242 - val_acc: 0.7749\n",
      "Epoch 97/100\n",
      "1563/1563 [==============================] - 27s 17ms/step - loss: 0.7693 - acc: 0.7501 - val_loss: 0.7015 - val_acc: 0.7767\n",
      "Epoch 98/100\n",
      "1563/1563 [==============================] - 26s 16ms/step - loss: 0.7654 - acc: 0.7474 - val_loss: 0.6305 - val_acc: 0.7961\n",
      "Epoch 99/100\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.7763 - acc: 0.7440 - val_loss: 0.6923 - val_acc: 0.7762\n",
      "Epoch 100/100\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.7698 - acc: 0.7490 - val_loss: 0.6485 - val_acc: 0.7863\n",
      "Saved trained model at D:\\Spring 2018\\AI\\Assignment-1\\saved_models\\keras_cifar10_trained_model.h5 \n",
      "10000/10000 [==============================] - 2s 176us/step\n",
      "Test loss: 0.6485102515220642\n",
      "Test accuracy: 0.7863\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import configparser\n",
    "import os\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"/Spring 2018/AI/Assignment-1/configuration-base.ini\")\n",
    "\n",
    "batch_size = int(config.get('Constants','batch_size'))\n",
    "num_classes = int(config.get('Constants','num_classes'))\n",
    "epochs = int(config.get('Constants','epochs'))\n",
    "data_augmentation = config.get('Constants','data_augmentation')\n",
    "num_predictions = int(config.get('Constants','num_predictions'))\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "\n",
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from configuration-1.ini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch_size = 64\t\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "data_augmentation = True\n",
    "num_predictions = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is even better with this set of parameters 81%. There is no major difference in train and test accuracies which shows that model has learnt well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/100\n",
      "782/782 [==============================] - 14s 18ms/step - loss: 1.9153 - acc: 0.2945 - val_loss: 1.6334 - val_acc: 0.4108\n",
      "Epoch 2/100\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 1.6446 - acc: 0.3955 - val_loss: 1.4634 - val_acc: 0.4616\n",
      "Epoch 3/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 1.5300 - acc: 0.4406 - val_loss: 1.4542 - val_acc: 0.4711\n",
      "Epoch 4/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 1.4587 - acc: 0.4692 - val_loss: 1.3386 - val_acc: 0.5140\n",
      "Epoch 5/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 1.3940 - acc: 0.4987 - val_loss: 1.2953 - val_acc: 0.5392\n",
      "Epoch 6/100\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 1.3442 - acc: 0.5182 - val_loss: 1.1876 - val_acc: 0.5848\n",
      "Epoch 7/100\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 1.3051 - acc: 0.5331 - val_loss: 1.1565 - val_acc: 0.5893\n",
      "Epoch 8/100\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 1.2592 - acc: 0.5513 - val_loss: 1.0911 - val_acc: 0.6154\n",
      "Epoch 9/100\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 1.2222 - acc: 0.5651 - val_loss: 1.1023 - val_acc: 0.6057\n",
      "Epoch 10/100\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 1.1843 - acc: 0.5788 - val_loss: 1.0155 - val_acc: 0.6385\n",
      "Epoch 11/100\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 1.1512 - acc: 0.5917 - val_loss: 1.0169 - val_acc: 0.6391\n",
      "Epoch 12/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 1.1225 - acc: 0.6015 - val_loss: 0.9567 - val_acc: 0.6632\n",
      "Epoch 13/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 1.0893 - acc: 0.6157 - val_loss: 0.9556 - val_acc: 0.6615\n",
      "Epoch 14/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 1.0681 - acc: 0.6220 - val_loss: 0.9091 - val_acc: 0.6798\n",
      "Epoch 15/100\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 1.0445 - acc: 0.6324 - val_loss: 0.9187 - val_acc: 0.6819\n",
      "Epoch 16/100\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 1.0272 - acc: 0.6393 - val_loss: 0.8895 - val_acc: 0.6908\n",
      "Epoch 17/100\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 1.0043 - acc: 0.6460 - val_loss: 0.8594 - val_acc: 0.6994\n",
      "Epoch 18/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.9865 - acc: 0.6548 - val_loss: 0.8379 - val_acc: 0.7057\n",
      "Epoch 19/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.9709 - acc: 0.6609 - val_loss: 0.8465 - val_acc: 0.7041\n",
      "Epoch 20/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.9555 - acc: 0.6641 - val_loss: 0.8513 - val_acc: 0.7040\n",
      "Epoch 21/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.9418 - acc: 0.6682 - val_loss: 0.7879 - val_acc: 0.7259\n",
      "Epoch 22/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.9245 - acc: 0.6752 - val_loss: 0.7880 - val_acc: 0.7244\n",
      "Epoch 23/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.9108 - acc: 0.6800 - val_loss: 0.7648 - val_acc: 0.7344\n",
      "Epoch 24/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.8948 - acc: 0.6849 - val_loss: 0.7672 - val_acc: 0.7357\n",
      "Epoch 25/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.8876 - acc: 0.6892 - val_loss: 0.7470 - val_acc: 0.7415\n",
      "Epoch 26/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.8723 - acc: 0.6935 - val_loss: 0.7529 - val_acc: 0.7373\n",
      "Epoch 27/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.8613 - acc: 0.7002 - val_loss: 0.7557 - val_acc: 0.7383\n",
      "Epoch 28/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.8514 - acc: 0.7038 - val_loss: 0.7102 - val_acc: 0.7524\n",
      "Epoch 29/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.8457 - acc: 0.7060 - val_loss: 0.7190 - val_acc: 0.7539\n",
      "Epoch 30/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.8323 - acc: 0.7095 - val_loss: 0.7196 - val_acc: 0.7497\n",
      "Epoch 31/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.8274 - acc: 0.7120 - val_loss: 0.6977 - val_acc: 0.7613\n",
      "Epoch 32/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.8177 - acc: 0.7138 - val_loss: 0.6819 - val_acc: 0.7660\n",
      "Epoch 33/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.8069 - acc: 0.7202 - val_loss: 0.6758 - val_acc: 0.7686\n",
      "Epoch 34/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.8040 - acc: 0.7219 - val_loss: 0.6758 - val_acc: 0.7661\n",
      "Epoch 35/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.7999 - acc: 0.7225 - val_loss: 0.7022 - val_acc: 0.7573\n",
      "Epoch 36/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.7891 - acc: 0.7250 - val_loss: 0.6564 - val_acc: 0.7750\n",
      "Epoch 37/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.7870 - acc: 0.7252 - val_loss: 0.6696 - val_acc: 0.7678\n",
      "Epoch 38/100\n",
      "782/782 [==============================] - 14s 17ms/step - loss: 0.7790 - acc: 0.7309 - val_loss: 0.6586 - val_acc: 0.7773\n",
      "Epoch 39/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.7751 - acc: 0.7293 - val_loss: 0.6368 - val_acc: 0.7816\n",
      "Epoch 40/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.7707 - acc: 0.7329 - val_loss: 0.6501 - val_acc: 0.7734\n",
      "Epoch 41/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.7632 - acc: 0.7365 - val_loss: 0.6517 - val_acc: 0.7767\n",
      "Epoch 42/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.7640 - acc: 0.7351 - val_loss: 0.6457 - val_acc: 0.7808\n",
      "Epoch 43/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.7575 - acc: 0.7379 - val_loss: 0.6311 - val_acc: 0.7836\n",
      "Epoch 44/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.7538 - acc: 0.7414 - val_loss: 0.6435 - val_acc: 0.7795\n",
      "Epoch 45/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.7498 - acc: 0.7403 - val_loss: 0.6171 - val_acc: 0.7940\n",
      "Epoch 46/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.7504 - acc: 0.7416 - val_loss: 0.6122 - val_acc: 0.7903\n",
      "Epoch 47/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.7436 - acc: 0.7433 - val_loss: 0.6096 - val_acc: 0.7908\n",
      "Epoch 48/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.7446 - acc: 0.7447 - val_loss: 0.6404 - val_acc: 0.7806\n",
      "Epoch 49/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.7401 - acc: 0.7441 - val_loss: 0.6229 - val_acc: 0.7878\n",
      "Epoch 50/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.7385 - acc: 0.7459 - val_loss: 0.6308 - val_acc: 0.7890\n",
      "Epoch 51/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.7318 - acc: 0.7489 - val_loss: 0.6088 - val_acc: 0.7968\n",
      "Epoch 52/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.7275 - acc: 0.7487 - val_loss: 0.5897 - val_acc: 0.7994\n",
      "Epoch 53/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.7259 - acc: 0.7509 - val_loss: 0.6375 - val_acc: 0.7856\n",
      "Epoch 54/100\n",
      "782/782 [==============================] - 14s 17ms/step - loss: 0.7260 - acc: 0.7492 - val_loss: 0.5943 - val_acc: 0.7973\n",
      "Epoch 55/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.7220 - acc: 0.7531 - val_loss: 0.6078 - val_acc: 0.7904\n",
      "Epoch 56/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.7158 - acc: 0.7554 - val_loss: 0.5929 - val_acc: 0.8030\n",
      "Epoch 57/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.7157 - acc: 0.7565 - val_loss: 0.6071 - val_acc: 0.7976\n",
      "Epoch 58/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.7172 - acc: 0.7555 - val_loss: 0.5923 - val_acc: 0.8005\n",
      "Epoch 59/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.7173 - acc: 0.7547 - val_loss: 0.6002 - val_acc: 0.7982\n",
      "Epoch 60/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.7105 - acc: 0.7592 - val_loss: 0.5816 - val_acc: 0.8017\n",
      "Epoch 61/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.7078 - acc: 0.7603 - val_loss: 0.5731 - val_acc: 0.8082\n",
      "Epoch 62/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.7110 - acc: 0.7580 - val_loss: 0.5981 - val_acc: 0.7981\n",
      "Epoch 63/100\n",
      "782/782 [==============================] - 14s 17ms/step - loss: 0.7078 - acc: 0.7591 - val_loss: 0.5820 - val_acc: 0.8055\n",
      "Epoch 64/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.7007 - acc: 0.7612 - val_loss: 0.5802 - val_acc: 0.8052\n",
      "Epoch 65/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.7018 - acc: 0.7612 - val_loss: 0.5819 - val_acc: 0.8051\n",
      "Epoch 66/100\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 0.7028 - acc: 0.7598 - val_loss: 0.5856 - val_acc: 0.8028\n",
      "Epoch 67/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.6964 - acc: 0.7644 - val_loss: 0.5957 - val_acc: 0.8021\n",
      "Epoch 68/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.6956 - acc: 0.7624 - val_loss: 0.5714 - val_acc: 0.8026\n",
      "Epoch 69/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.6979 - acc: 0.7629 - val_loss: 0.5836 - val_acc: 0.8052\n",
      "Epoch 70/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.6926 - acc: 0.7642 - val_loss: 0.5734 - val_acc: 0.8095\n",
      "Epoch 71/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.6907 - acc: 0.7655 - val_loss: 0.5755 - val_acc: 0.8066\n",
      "Epoch 72/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.6883 - acc: 0.7652 - val_loss: 0.5572 - val_acc: 0.8114\n",
      "Epoch 73/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.6896 - acc: 0.7656 - val_loss: 0.5666 - val_acc: 0.8093\n",
      "Epoch 74/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.6863 - acc: 0.7646 - val_loss: 0.5745 - val_acc: 0.8055\n",
      "Epoch 75/100\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 0.6870 - acc: 0.7658 - val_loss: 0.5673 - val_acc: 0.8102\n",
      "Epoch 76/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.6858 - acc: 0.7675 - val_loss: 0.5704 - val_acc: 0.8097\n",
      "Epoch 77/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.6806 - acc: 0.7705 - val_loss: 0.5594 - val_acc: 0.8109\n",
      "Epoch 78/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.6801 - acc: 0.7684 - val_loss: 0.5939 - val_acc: 0.8057\n",
      "Epoch 79/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.6831 - acc: 0.7686 - val_loss: 0.5668 - val_acc: 0.8121\n",
      "Epoch 80/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.6770 - acc: 0.7697 - val_loss: 0.5589 - val_acc: 0.8122\n",
      "Epoch 81/100\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 0.6760 - acc: 0.7714 - val_loss: 0.5583 - val_acc: 0.8127\n",
      "Epoch 82/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.6712 - acc: 0.7723 - val_loss: 0.5625 - val_acc: 0.8126\n",
      "Epoch 83/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.6796 - acc: 0.7711 - val_loss: 0.5517 - val_acc: 0.8124\n",
      "Epoch 84/100\n",
      "782/782 [==============================] - 14s 17ms/step - loss: 0.6747 - acc: 0.7716 - val_loss: 0.5469 - val_acc: 0.8146\n",
      "Epoch 85/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.6718 - acc: 0.7725 - val_loss: 0.5539 - val_acc: 0.8151\n",
      "Epoch 86/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.6772 - acc: 0.7736 - val_loss: 0.5465 - val_acc: 0.8161\n",
      "Epoch 87/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.6693 - acc: 0.7743 - val_loss: 0.5638 - val_acc: 0.8089\n",
      "Epoch 88/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.6627 - acc: 0.7753 - val_loss: 0.5548 - val_acc: 0.8128\n",
      "Epoch 89/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.6693 - acc: 0.7740 - val_loss: 0.5521 - val_acc: 0.8154\n",
      "Epoch 90/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.6710 - acc: 0.7752 - val_loss: 0.5684 - val_acc: 0.8134\n",
      "Epoch 91/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.6664 - acc: 0.7753 - val_loss: 0.5533 - val_acc: 0.8163\n",
      "Epoch 92/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.6636 - acc: 0.7750 - val_loss: 0.5488 - val_acc: 0.8136\n",
      "Epoch 93/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.6655 - acc: 0.7751 - val_loss: 0.5689 - val_acc: 0.8101\n",
      "Epoch 94/100\n",
      "782/782 [==============================] - 14s 18ms/step - loss: 0.6615 - acc: 0.7792 - val_loss: 0.5661 - val_acc: 0.8162\n",
      "Epoch 95/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.6624 - acc: 0.7789 - val_loss: 0.5503 - val_acc: 0.8150\n",
      "Epoch 96/100\n",
      "782/782 [==============================] - 14s 17ms/step - loss: 0.6588 - acc: 0.7767 - val_loss: 0.5363 - val_acc: 0.8195\n",
      "Epoch 97/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.6577 - acc: 0.7773 - val_loss: 0.5413 - val_acc: 0.8206\n",
      "Epoch 98/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.6570 - acc: 0.7783 - val_loss: 0.5495 - val_acc: 0.8167\n",
      "Epoch 99/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.6577 - acc: 0.7794 - val_loss: 0.5462 - val_acc: 0.8151\n",
      "Epoch 100/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.6551 - acc: 0.7816 - val_loss: 0.5580 - val_acc: 0.8157\n",
      "Saved trained model at D:\\Spring 2018\\AI\\Assignment-1\\saved_models\\keras_cifar10_trained_model.h5 \n",
      "10000/10000 [==============================] - 1s 137us/step\n",
      "Test loss: 0.5579676724433899\n",
      "Test accuracy: 0.8157\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import configparser\n",
    "import os\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"/Spring 2018/AI/Assignment-1/configuration-1.ini\")\n",
    "\n",
    "batch_size = int(config.get('Constants','batch_size'))\n",
    "num_classes = int(config.get('Constants','num_classes'))\n",
    "epochs = int(config.get('Constants','epochs'))\n",
    "data_augmentation = config.get('Constants','data_augmentation')\n",
    "num_predictions = int(config.get('Constants','num_predictions'))\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "\n",
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from configuration-2.ini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch_size = 128\t\n",
    "num_classes = 10\n",
    "epochs = 200\n",
    "data_augmentation = True\n",
    "num_predictions = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test accuracy is better with this set of parameters, 84% and the model has learnt well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 1.9790 - acc: 0.2727 - val_loss: 1.7192 - val_acc: 0.3868\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 1.7259 - acc: 0.3704 - val_loss: 1.5607 - val_acc: 0.4417\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1.6131 - acc: 0.4088 - val_loss: 1.4507 - val_acc: 0.4776\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1.5346 - acc: 0.4414 - val_loss: 1.3922 - val_acc: 0.5077\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.4765 - acc: 0.4642 - val_loss: 1.3174 - val_acc: 0.5331\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.4249 - acc: 0.4844 - val_loss: 1.2710 - val_acc: 0.5526\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.3875 - acc: 0.5015 - val_loss: 1.2625 - val_acc: 0.5493\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1.3529 - acc: 0.5134 - val_loss: 1.2004 - val_acc: 0.5790\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 1.3227 - acc: 0.5266 - val_loss: 1.1708 - val_acc: 0.5885\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 1.2981 - acc: 0.5385 - val_loss: 1.1355 - val_acc: 0.6056\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 1.2674 - acc: 0.5486 - val_loss: 1.1062 - val_acc: 0.6117\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1.2391 - acc: 0.5597 - val_loss: 1.1135 - val_acc: 0.6108\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.2152 - acc: 0.5676 - val_loss: 1.0597 - val_acc: 0.6298\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.1880 - acc: 0.5768 - val_loss: 1.0691 - val_acc: 0.6271\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.1675 - acc: 0.5869 - val_loss: 1.0226 - val_acc: 0.6447\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1.1464 - acc: 0.5945 - val_loss: 1.0016 - val_acc: 0.6509\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 1.1288 - acc: 0.6008 - val_loss: 0.9737 - val_acc: 0.6640\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 1.1103 - acc: 0.6067 - val_loss: 0.9513 - val_acc: 0.6671\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 1.0910 - acc: 0.6122 - val_loss: 0.9622 - val_acc: 0.6686\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1.0736 - acc: 0.6216 - val_loss: 0.9362 - val_acc: 0.6725\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.0628 - acc: 0.6230 - val_loss: 0.9085 - val_acc: 0.6858\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.0450 - acc: 0.6306 - val_loss: 0.9094 - val_acc: 0.6833\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1.0297 - acc: 0.6356 - val_loss: 0.8970 - val_acc: 0.6878\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1.0170 - acc: 0.6418 - val_loss: 0.9233 - val_acc: 0.6807\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.9964 - acc: 0.6487 - val_loss: 0.8548 - val_acc: 0.7030\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 13s 32ms/step - loss: 0.9825 - acc: 0.6537 - val_loss: 0.8496 - val_acc: 0.7036\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.9713 - acc: 0.6594 - val_loss: 0.8353 - val_acc: 0.7110\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.9646 - acc: 0.6592 - val_loss: 0.8431 - val_acc: 0.7099\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.9513 - acc: 0.6654 - val_loss: 0.8468 - val_acc: 0.7050\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9421 - acc: 0.6675 - val_loss: 0.7825 - val_acc: 0.7305\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.9284 - acc: 0.6726 - val_loss: 0.7877 - val_acc: 0.7298\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.9195 - acc: 0.6778 - val_loss: 0.7821 - val_acc: 0.7249\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.9103 - acc: 0.6809 - val_loss: 0.7914 - val_acc: 0.7270\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.9006 - acc: 0.6839 - val_loss: 0.7717 - val_acc: 0.7343\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.8885 - acc: 0.6901 - val_loss: 0.7438 - val_acc: 0.7467\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.8775 - acc: 0.6928 - val_loss: 0.7401 - val_acc: 0.7476\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.8685 - acc: 0.6948 - val_loss: 0.7458 - val_acc: 0.7418\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.8628 - acc: 0.6971 - val_loss: 0.7241 - val_acc: 0.7521\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.8526 - acc: 0.7009 - val_loss: 0.7278 - val_acc: 0.7554\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.8476 - acc: 0.7051 - val_loss: 0.7454 - val_acc: 0.7454\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.8374 - acc: 0.7062 - val_loss: 0.7152 - val_acc: 0.7527\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.8326 - acc: 0.7089 - val_loss: 0.7110 - val_acc: 0.7554\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.8249 - acc: 0.7125 - val_loss: 0.7219 - val_acc: 0.7525\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.8181 - acc: 0.7168 - val_loss: 0.6910 - val_acc: 0.7631\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.8110 - acc: 0.7175 - val_loss: 0.6779 - val_acc: 0.7653\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.8057 - acc: 0.7214 - val_loss: 0.6906 - val_acc: 0.7631\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.7950 - acc: 0.7219 - val_loss: 0.6709 - val_acc: 0.7673\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.7908 - acc: 0.7245 - val_loss: 0.6756 - val_acc: 0.7675\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.7831 - acc: 0.7277 - val_loss: 0.6670 - val_acc: 0.7729\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.7811 - acc: 0.7274 - val_loss: 0.6559 - val_acc: 0.7733\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.7719 - acc: 0.7300 - val_loss: 0.6690 - val_acc: 0.7736\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.7687 - acc: 0.7323 - val_loss: 0.6800 - val_acc: 0.7664\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.7632 - acc: 0.7343 - val_loss: 0.6448 - val_acc: 0.7775\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.7573 - acc: 0.7359 - val_loss: 0.6397 - val_acc: 0.7804\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.7537 - acc: 0.7379 - val_loss: 0.6440 - val_acc: 0.7767\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.7497 - acc: 0.7400 - val_loss: 0.6481 - val_acc: 0.7781\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.7476 - acc: 0.7391 - val_loss: 0.6280 - val_acc: 0.7837\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.7462 - acc: 0.7389 - val_loss: 0.6578 - val_acc: 0.7720\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.7397 - acc: 0.7440 - val_loss: 0.6439 - val_acc: 0.7825\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.7380 - acc: 0.7446 - val_loss: 0.6382 - val_acc: 0.7806\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.7308 - acc: 0.7472 - val_loss: 0.6247 - val_acc: 0.7873\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.7338 - acc: 0.7452 - val_loss: 0.6151 - val_acc: 0.7896\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.7197 - acc: 0.7496 - val_loss: 0.6149 - val_acc: 0.7918\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.7240 - acc: 0.7500 - val_loss: 0.6113 - val_acc: 0.7893\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.7242 - acc: 0.7508 - val_loss: 0.6041 - val_acc: 0.7931\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.7176 - acc: 0.7522 - val_loss: 0.6030 - val_acc: 0.7935\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.7122 - acc: 0.7540 - val_loss: 0.6044 - val_acc: 0.7912\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.7139 - acc: 0.7505 - val_loss: 0.6017 - val_acc: 0.7929\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.7094 - acc: 0.7548 - val_loss: 0.6002 - val_acc: 0.7923\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.7044 - acc: 0.7552 - val_loss: 0.5992 - val_acc: 0.7955\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.7058 - acc: 0.7545 - val_loss: 0.5896 - val_acc: 0.7959\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.7036 - acc: 0.7597 - val_loss: 0.6048 - val_acc: 0.7942\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6991 - acc: 0.7577 - val_loss: 0.5931 - val_acc: 0.7954\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6973 - acc: 0.7615 - val_loss: 0.6086 - val_acc: 0.7942\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6934 - acc: 0.7628 - val_loss: 0.5901 - val_acc: 0.8026\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.6932 - acc: 0.7617 - val_loss: 0.5853 - val_acc: 0.7988\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.6882 - acc: 0.7608 - val_loss: 0.5853 - val_acc: 0.7972\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.6853 - acc: 0.7644 - val_loss: 0.5799 - val_acc: 0.7994\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.6862 - acc: 0.7613 - val_loss: 0.5694 - val_acc: 0.8058\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.6843 - acc: 0.7631 - val_loss: 0.5772 - val_acc: 0.8050\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6832 - acc: 0.7638 - val_loss: 0.5777 - val_acc: 0.8026\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6806 - acc: 0.7666 - val_loss: 0.5706 - val_acc: 0.8055\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6782 - acc: 0.7681 - val_loss: 0.5728 - val_acc: 0.8060\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.6739 - acc: 0.7657 - val_loss: 0.5718 - val_acc: 0.8016\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.6791 - acc: 0.7641 - val_loss: 0.5614 - val_acc: 0.8067\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6735 - acc: 0.7687 - val_loss: 0.5738 - val_acc: 0.8035\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.6751 - acc: 0.7690 - val_loss: 0.5770 - val_acc: 0.8046\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6656 - acc: 0.7701 - val_loss: 0.5576 - val_acc: 0.8068\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6727 - acc: 0.7693 - val_loss: 0.5604 - val_acc: 0.8099\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6650 - acc: 0.7738 - val_loss: 0.5746 - val_acc: 0.8076\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6652 - acc: 0.7716 - val_loss: 0.5672 - val_acc: 0.8081\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6610 - acc: 0.7723 - val_loss: 0.5555 - val_acc: 0.8094\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.6592 - acc: 0.7753 - val_loss: 0.5574 - val_acc: 0.8087\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.6587 - acc: 0.7742 - val_loss: 0.5744 - val_acc: 0.8047\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.6545 - acc: 0.7743 - val_loss: 0.5543 - val_acc: 0.8107\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6554 - acc: 0.7757 - val_loss: 0.5685 - val_acc: 0.8077\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6558 - acc: 0.7749 - val_loss: 0.5475 - val_acc: 0.8147\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6508 - acc: 0.7769 - val_loss: 0.5717 - val_acc: 0.8049\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6487 - acc: 0.7782 - val_loss: 0.5670 - val_acc: 0.8105\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6509 - acc: 0.7761 - val_loss: 0.5449 - val_acc: 0.8141\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6459 - acc: 0.7785 - val_loss: 0.5537 - val_acc: 0.8136\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6493 - acc: 0.7781 - val_loss: 0.5634 - val_acc: 0.8078\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6532 - acc: 0.7778 - val_loss: 0.5562 - val_acc: 0.8104\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6464 - acc: 0.7774 - val_loss: 0.5409 - val_acc: 0.8158\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6426 - acc: 0.7800 - val_loss: 0.5486 - val_acc: 0.8170\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.6432 - acc: 0.7814 - val_loss: 0.5397 - val_acc: 0.8153\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6392 - acc: 0.7818 - val_loss: 0.5495 - val_acc: 0.8118\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6408 - acc: 0.7791 - val_loss: 0.5513 - val_acc: 0.8147\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6372 - acc: 0.7822 - val_loss: 0.5474 - val_acc: 0.8160\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6374 - acc: 0.7806 - val_loss: 0.5414 - val_acc: 0.8193\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6354 - acc: 0.7825 - val_loss: 0.5409 - val_acc: 0.8164\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6372 - acc: 0.7846 - val_loss: 0.5433 - val_acc: 0.8158\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6347 - acc: 0.7832 - val_loss: 0.5418 - val_acc: 0.8173\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.6314 - acc: 0.7840 - val_loss: 0.5491 - val_acc: 0.8172\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.6348 - acc: 0.7857 - val_loss: 0.5359 - val_acc: 0.8161\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6308 - acc: 0.7861 - val_loss: 0.5339 - val_acc: 0.8181\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6336 - acc: 0.7852 - val_loss: 0.5331 - val_acc: 0.8173\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6298 - acc: 0.7852 - val_loss: 0.5429 - val_acc: 0.8174\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6307 - acc: 0.7863 - val_loss: 0.5306 - val_acc: 0.8200\n",
      "Epoch 120/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6300 - acc: 0.7859 - val_loss: 0.5301 - val_acc: 0.8214\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.6285 - acc: 0.7864 - val_loss: 0.5353 - val_acc: 0.8168\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.6223 - acc: 0.7886 - val_loss: 0.5376 - val_acc: 0.8157\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6215 - acc: 0.7902 - val_loss: 0.5266 - val_acc: 0.8213\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6243 - acc: 0.7880 - val_loss: 0.5236 - val_acc: 0.8228\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6218 - acc: 0.7882 - val_loss: 0.5375 - val_acc: 0.8205\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.6218 - acc: 0.7895 - val_loss: 0.5270 - val_acc: 0.8192\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6185 - acc: 0.7899 - val_loss: 0.5188 - val_acc: 0.8234\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6119 - acc: 0.7914 - val_loss: 0.5276 - val_acc: 0.8208\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6185 - acc: 0.7883 - val_loss: 0.5257 - val_acc: 0.8201\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.6163 - acc: 0.7897 - val_loss: 0.5229 - val_acc: 0.8257\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6076 - acc: 0.7933 - val_loss: 0.5447 - val_acc: 0.8176\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6120 - acc: 0.7909 - val_loss: 0.5129 - val_acc: 0.8261\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6087 - acc: 0.7930 - val_loss: 0.5208 - val_acc: 0.8253\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.6119 - acc: 0.7927 - val_loss: 0.5103 - val_acc: 0.8256\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6101 - acc: 0.7952 - val_loss: 0.5307 - val_acc: 0.8213\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6035 - acc: 0.7946 - val_loss: 0.5273 - val_acc: 0.8242\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6076 - acc: 0.7963 - val_loss: 0.5278 - val_acc: 0.8236\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.6074 - acc: 0.7930 - val_loss: 0.5161 - val_acc: 0.8265\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.6100 - acc: 0.7944 - val_loss: 0.5046 - val_acc: 0.8275\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6043 - acc: 0.7949 - val_loss: 0.5240 - val_acc: 0.8213\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6064 - acc: 0.7946 - val_loss: 0.5312 - val_acc: 0.8241\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6070 - acc: 0.7961 - val_loss: 0.5098 - val_acc: 0.8288\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6060 - acc: 0.7961 - val_loss: 0.5197 - val_acc: 0.8248\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5996 - acc: 0.7964 - val_loss: 0.5052 - val_acc: 0.8291\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.6035 - acc: 0.7975 - val_loss: 0.4954 - val_acc: 0.8335\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5988 - acc: 0.7975 - val_loss: 0.5130 - val_acc: 0.8259\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.6011 - acc: 0.7967 - val_loss: 0.4936 - val_acc: 0.8336\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.6045 - acc: 0.7952 - val_loss: 0.5127 - val_acc: 0.8253\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6040 - acc: 0.7948 - val_loss: 0.5048 - val_acc: 0.8312\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5980 - acc: 0.7969 - val_loss: 0.5312 - val_acc: 0.8242\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5952 - acc: 0.7994 - val_loss: 0.4993 - val_acc: 0.8330\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5930 - acc: 0.8002 - val_loss: 0.5163 - val_acc: 0.8255\n",
      "Epoch 153/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5967 - acc: 0.7982 - val_loss: 0.4995 - val_acc: 0.8323\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5934 - acc: 0.7996 - val_loss: 0.4973 - val_acc: 0.8336\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5983 - acc: 0.7986 - val_loss: 0.5114 - val_acc: 0.8249\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5970 - acc: 0.7974 - val_loss: 0.5299 - val_acc: 0.8216\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5888 - acc: 0.8004 - val_loss: 0.5111 - val_acc: 0.8294\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5890 - acc: 0.8012 - val_loss: 0.4890 - val_acc: 0.8366\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5891 - acc: 0.7999 - val_loss: 0.4972 - val_acc: 0.8326\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5927 - acc: 0.7998 - val_loss: 0.4905 - val_acc: 0.8359\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5906 - acc: 0.8008 - val_loss: 0.4932 - val_acc: 0.8337\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5834 - acc: 0.8044 - val_loss: 0.4983 - val_acc: 0.8319\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5849 - acc: 0.8038 - val_loss: 0.4932 - val_acc: 0.8356\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5860 - acc: 0.8024 - val_loss: 0.5007 - val_acc: 0.8305\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5868 - acc: 0.8018 - val_loss: 0.4958 - val_acc: 0.8352\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5846 - acc: 0.8032 - val_loss: 0.4959 - val_acc: 0.8303\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5839 - acc: 0.8053 - val_loss: 0.4837 - val_acc: 0.8366\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5813 - acc: 0.8050 - val_loss: 0.5220 - val_acc: 0.8241\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5854 - acc: 0.8014 - val_loss: 0.5036 - val_acc: 0.8328\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5872 - acc: 0.8021 - val_loss: 0.4972 - val_acc: 0.8327\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5762 - acc: 0.8063 - val_loss: 0.4923 - val_acc: 0.8366\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5814 - acc: 0.8041 - val_loss: 0.4965 - val_acc: 0.8317\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5820 - acc: 0.8050 - val_loss: 0.5028 - val_acc: 0.8318\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5773 - acc: 0.8047 - val_loss: 0.4960 - val_acc: 0.8347\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5724 - acc: 0.8078 - val_loss: 0.4812 - val_acc: 0.8387\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5778 - acc: 0.8078 - val_loss: 0.5157 - val_acc: 0.8260\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5828 - acc: 0.8033 - val_loss: 0.5039 - val_acc: 0.8295\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5757 - acc: 0.8061 - val_loss: 0.4892 - val_acc: 0.8372\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5737 - acc: 0.8062 - val_loss: 0.4893 - val_acc: 0.8367\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5725 - acc: 0.8084 - val_loss: 0.4824 - val_acc: 0.8383\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5788 - acc: 0.8043 - val_loss: 0.4892 - val_acc: 0.8346\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5737 - acc: 0.8067 - val_loss: 0.4937 - val_acc: 0.8348\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5739 - acc: 0.8072 - val_loss: 0.4924 - val_acc: 0.8362\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5724 - acc: 0.8067 - val_loss: 0.4998 - val_acc: 0.8328\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5721 - acc: 0.8089 - val_loss: 0.4786 - val_acc: 0.8395\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5696 - acc: 0.8080 - val_loss: 0.4857 - val_acc: 0.8356\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5746 - acc: 0.8072 - val_loss: 0.4839 - val_acc: 0.8370\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5723 - acc: 0.8092 - val_loss: 0.4922 - val_acc: 0.8366\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5741 - acc: 0.8086 - val_loss: 0.4895 - val_acc: 0.8352\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5694 - acc: 0.8076 - val_loss: 0.4860 - val_acc: 0.8379\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5710 - acc: 0.8100 - val_loss: 0.4889 - val_acc: 0.8371\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5716 - acc: 0.8083 - val_loss: 0.5022 - val_acc: 0.8330\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5755 - acc: 0.8063 - val_loss: 0.4929 - val_acc: 0.8383\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5630 - acc: 0.8118 - val_loss: 0.4839 - val_acc: 0.8362\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5698 - acc: 0.8084 - val_loss: 0.4939 - val_acc: 0.8355\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5707 - acc: 0.8104 - val_loss: 0.4808 - val_acc: 0.8413\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5661 - acc: 0.8099 - val_loss: 0.4788 - val_acc: 0.8380\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5659 - acc: 0.8093 - val_loss: 0.4780 - val_acc: 0.8406\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5663 - acc: 0.8093 - val_loss: 0.4731 - val_acc: 0.8399\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5656 - acc: 0.8099 - val_loss: 0.4775 - val_acc: 0.8410\n",
      "Saved trained model at D:\\Spring 2018\\AI\\Assignment-1\\saved_models\\keras_cifar10_trained_model.h5 \n",
      "10000/10000 [==============================] - 1s 120us/step\n",
      "Test loss: 0.4774998920917511\n",
      "Test accuracy: 0.841\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import configparser\n",
    "import os\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"/Spring 2018/AI/Assignment-1/configuration-2.ini\")\n",
    "\n",
    "batch_size = int(config.get('Constants','batch_size'))\n",
    "num_classes = int(config.get('Constants','num_classes'))\n",
    "epochs = int(config.get('Constants','epochs'))\n",
    "data_augmentation = config.get('Constants','data_augmentation')\n",
    "num_predictions = int(config.get('Constants','num_predictions'))\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "\n",
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from configuration-3.ini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch_size = 256\t\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "data_augmentation = False\n",
    "num_predictions = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model gives a lower accuracy of 79%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/100\n",
      "196/196 [==============================] - 26s 134ms/step - loss: 2.0754 - acc: 0.2298 - val_loss: 1.8548 - val_acc: 0.3462\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 1.8259 - acc: 0.3360 - val_loss: 1.6977 - val_acc: 0.3986\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 31s 160ms/step - loss: 1.7248 - acc: 0.3717 - val_loss: 1.5891 - val_acc: 0.4334\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 1.6551 - acc: 0.3976 - val_loss: 1.5595 - val_acc: 0.4378\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 27s 140ms/step - loss: 1.5992 - acc: 0.4166 - val_loss: 1.4726 - val_acc: 0.4695\n",
      "Epoch 6/100\n",
      "196/196 [==============================] - 23s 120ms/step - loss: 1.5491 - acc: 0.4344 - val_loss: 1.4501 - val_acc: 0.4862\n",
      "Epoch 7/100\n",
      "196/196 [==============================] - 24s 121ms/step - loss: 1.5097 - acc: 0.4522 - val_loss: 1.3761 - val_acc: 0.5110\n",
      "Epoch 8/100\n",
      "196/196 [==============================] - 21s 108ms/step - loss: 1.4765 - acc: 0.4626 - val_loss: 1.3384 - val_acc: 0.5307\n",
      "Epoch 9/100\n",
      "196/196 [==============================] - 24s 120ms/step - loss: 1.4473 - acc: 0.4756 - val_loss: 1.2970 - val_acc: 0.5428\n",
      "Epoch 10/100\n",
      "196/196 [==============================] - 23s 118ms/step - loss: 1.4105 - acc: 0.4910 - val_loss: 1.2625 - val_acc: 0.5558\n",
      "Epoch 11/100\n",
      "196/196 [==============================] - 27s 138ms/step - loss: 1.3851 - acc: 0.4995 - val_loss: 1.2475 - val_acc: 0.5583\n",
      "Epoch 12/100\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 1.3627 - acc: 0.5116 - val_loss: 1.2426 - val_acc: 0.5589\n",
      "Epoch 13/100\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 1.3386 - acc: 0.5204 - val_loss: 1.2241 - val_acc: 0.5674\n",
      "Epoch 14/100\n",
      "196/196 [==============================] - 29s 147ms/step - loss: 1.3175 - acc: 0.5288 - val_loss: 1.1889 - val_acc: 0.5813\n",
      "Epoch 15/100\n",
      "196/196 [==============================] - 23s 119ms/step - loss: 1.2922 - acc: 0.5370 - val_loss: 1.1646 - val_acc: 0.5906\n",
      "Epoch 16/100\n",
      "196/196 [==============================] - 28s 145ms/step - loss: 1.2722 - acc: 0.5449 - val_loss: 1.1306 - val_acc: 0.5999\n",
      "Epoch 17/100\n",
      "196/196 [==============================] - 26s 130ms/step - loss: 1.2515 - acc: 0.5553 - val_loss: 1.1351 - val_acc: 0.6012\n",
      "Epoch 18/100\n",
      "196/196 [==============================] - 27s 138ms/step - loss: 1.2343 - acc: 0.5581 - val_loss: 1.0789 - val_acc: 0.6179\n",
      "Epoch 19/100\n",
      "196/196 [==============================] - 26s 135ms/step - loss: 1.2185 - acc: 0.5672 - val_loss: 1.0662 - val_acc: 0.6228\n",
      "Epoch 20/100\n",
      "196/196 [==============================] - 29s 146ms/step - loss: 1.1993 - acc: 0.5752 - val_loss: 1.0604 - val_acc: 0.6263\n",
      "Epoch 21/100\n",
      "196/196 [==============================] - 28s 141ms/step - loss: 1.1876 - acc: 0.5771 - val_loss: 1.0389 - val_acc: 0.6366\n",
      "Epoch 22/100\n",
      "196/196 [==============================] - 29s 146ms/step - loss: 1.1717 - acc: 0.5824 - val_loss: 1.0351 - val_acc: 0.6344\n",
      "Epoch 23/100\n",
      "196/196 [==============================] - 29s 146ms/step - loss: 1.1566 - acc: 0.5901 - val_loss: 1.0194 - val_acc: 0.6426\n",
      "Epoch 24/100\n",
      "196/196 [==============================] - 25s 126ms/step - loss: 1.1411 - acc: 0.5958 - val_loss: 1.0185 - val_acc: 0.6423\n",
      "Epoch 25/100\n",
      "196/196 [==============================] - 27s 136ms/step - loss: 1.1296 - acc: 0.5999 - val_loss: 1.0038 - val_acc: 0.6487\n",
      "Epoch 26/100\n",
      "196/196 [==============================] - 25s 127ms/step - loss: 1.1181 - acc: 0.6038 - val_loss: 0.9721 - val_acc: 0.6568\n",
      "Epoch 27/100\n",
      "196/196 [==============================] - 25s 130ms/step - loss: 1.1100 - acc: 0.6068 - val_loss: 0.9650 - val_acc: 0.6592\n",
      "Epoch 28/100\n",
      "196/196 [==============================] - 24s 121ms/step - loss: 1.0972 - acc: 0.6119 - val_loss: 0.9533 - val_acc: 0.6689\n",
      "Epoch 29/100\n",
      "196/196 [==============================] - 26s 131ms/step - loss: 1.0861 - acc: 0.6138 - val_loss: 0.9375 - val_acc: 0.6700\n",
      "Epoch 30/100\n",
      "196/196 [==============================] - 26s 135ms/step - loss: 1.0766 - acc: 0.6203 - val_loss: 0.9225 - val_acc: 0.6758\n",
      "Epoch 31/100\n",
      "196/196 [==============================] - 28s 144ms/step - loss: 1.0603 - acc: 0.6238 - val_loss: 0.9105 - val_acc: 0.6820\n",
      "Epoch 32/100\n",
      "196/196 [==============================] - 25s 126ms/step - loss: 1.0526 - acc: 0.6294 - val_loss: 0.9381 - val_acc: 0.6706\n",
      "Epoch 33/100\n",
      "196/196 [==============================] - 27s 137ms/step - loss: 1.0427 - acc: 0.6321 - val_loss: 0.8914 - val_acc: 0.6858\n",
      "Epoch 34/100\n",
      "196/196 [==============================] - 24s 121ms/step - loss: 1.0374 - acc: 0.6341 - val_loss: 0.8915 - val_acc: 0.6867\n",
      "Epoch 35/100\n",
      "196/196 [==============================] - 25s 128ms/step - loss: 1.0287 - acc: 0.6374 - val_loss: 0.8991 - val_acc: 0.6822\n",
      "Epoch 36/100\n",
      "196/196 [==============================] - 24s 120ms/step - loss: 1.0174 - acc: 0.6423 - val_loss: 0.8912 - val_acc: 0.6865\n",
      "Epoch 37/100\n",
      "196/196 [==============================] - 26s 134ms/step - loss: 0.9981 - acc: 0.6471 - val_loss: 0.8640 - val_acc: 0.6969\n",
      "Epoch 38/100\n",
      "196/196 [==============================] - 25s 126ms/step - loss: 1.0002 - acc: 0.6465 - val_loss: 0.8517 - val_acc: 0.7008\n",
      "Epoch 39/100\n",
      "196/196 [==============================] - 22s 114ms/step - loss: 0.9944 - acc: 0.6488 - val_loss: 0.8488 - val_acc: 0.7030\n",
      "Epoch 40/100\n",
      "196/196 [==============================] - 27s 136ms/step - loss: 0.9850 - acc: 0.6515 - val_loss: 0.8546 - val_acc: 0.7006\n",
      "Epoch 41/100\n",
      "196/196 [==============================] - 25s 127ms/step - loss: 0.9781 - acc: 0.6549 - val_loss: 0.8452 - val_acc: 0.7034\n",
      "Epoch 42/100\n",
      "196/196 [==============================] - 24s 122ms/step - loss: 0.9702 - acc: 0.6599 - val_loss: 0.8587 - val_acc: 0.6991\n",
      "Epoch 43/100\n",
      "196/196 [==============================] - 27s 137ms/step - loss: 0.9631 - acc: 0.6623 - val_loss: 0.8204 - val_acc: 0.7152\n",
      "Epoch 44/100\n",
      "196/196 [==============================] - 24s 123ms/step - loss: 0.9536 - acc: 0.6668 - val_loss: 0.8418 - val_acc: 0.7019\n",
      "Epoch 45/100\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 0.9462 - acc: 0.6671 - val_loss: 0.8162 - val_acc: 0.7134\n",
      "Epoch 46/100\n",
      "196/196 [==============================] - 10s 51ms/step - loss: 0.9385 - acc: 0.6709 - val_loss: 0.7987 - val_acc: 0.7224\n",
      "Epoch 47/100\n",
      "196/196 [==============================] - 10s 51ms/step - loss: 0.9314 - acc: 0.6732 - val_loss: 0.8007 - val_acc: 0.7178\n",
      "Epoch 48/100\n",
      "196/196 [==============================] - 10s 52ms/step - loss: 0.9270 - acc: 0.6735 - val_loss: 0.8020 - val_acc: 0.7180\n",
      "Epoch 49/100\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.9203 - acc: 0.6768 - val_loss: 0.7963 - val_acc: 0.7198\n",
      "Epoch 50/100\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.9144 - acc: 0.6798 - val_loss: 0.7793 - val_acc: 0.7274\n",
      "Epoch 51/100\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.9017 - acc: 0.6810 - val_loss: 0.7993 - val_acc: 0.7206\n",
      "Epoch 52/100\n",
      "196/196 [==============================] - 10s 52ms/step - loss: 0.9020 - acc: 0.6845 - val_loss: 0.7769 - val_acc: 0.7264\n",
      "Epoch 53/100\n",
      "196/196 [==============================] - 10s 52ms/step - loss: 0.8986 - acc: 0.6856 - val_loss: 0.7744 - val_acc: 0.7338\n",
      "Epoch 54/100\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.8884 - acc: 0.6868 - val_loss: 0.7677 - val_acc: 0.7320\n",
      "Epoch 55/100\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.8863 - acc: 0.6896 - val_loss: 0.7651 - val_acc: 0.7374\n",
      "Epoch 56/100\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.8764 - acc: 0.6926 - val_loss: 0.7467 - val_acc: 0.7389\n",
      "Epoch 57/100\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.8720 - acc: 0.6943 - val_loss: 0.7526 - val_acc: 0.7369\n",
      "Epoch 58/100\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.8700 - acc: 0.6939 - val_loss: 0.7354 - val_acc: 0.7433\n",
      "Epoch 59/100\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.8643 - acc: 0.6962 - val_loss: 0.7526 - val_acc: 0.7394\n",
      "Epoch 60/100\n",
      "196/196 [==============================] - 10s 52ms/step - loss: 0.8551 - acc: 0.6998 - val_loss: 0.7191 - val_acc: 0.7477\n",
      "Epoch 61/100\n",
      "196/196 [==============================] - 10s 52ms/step - loss: 0.8524 - acc: 0.7023 - val_loss: 0.7319 - val_acc: 0.7472\n",
      "Epoch 62/100\n",
      "196/196 [==============================] - 10s 52ms/step - loss: 0.8502 - acc: 0.6995 - val_loss: 0.7289 - val_acc: 0.7470\n",
      "Epoch 63/100\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.8399 - acc: 0.7052 - val_loss: 0.7347 - val_acc: 0.7415\n",
      "Epoch 64/100\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.8360 - acc: 0.7084 - val_loss: 0.7196 - val_acc: 0.7507\n",
      "Epoch 65/100\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.8315 - acc: 0.7076 - val_loss: 0.7159 - val_acc: 0.7499\n",
      "Epoch 66/100\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.8325 - acc: 0.7087 - val_loss: 0.7053 - val_acc: 0.7534\n",
      "Epoch 67/100\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.8281 - acc: 0.7116 - val_loss: 0.7021 - val_acc: 0.7541\n",
      "Epoch 68/100\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.8219 - acc: 0.7109 - val_loss: 0.7023 - val_acc: 0.7583\n",
      "Epoch 69/100\n",
      "196/196 [==============================] - 10s 52ms/step - loss: 0.8161 - acc: 0.7133 - val_loss: 0.6937 - val_acc: 0.7593\n",
      "Epoch 70/100\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.8099 - acc: 0.7148 - val_loss: 0.6845 - val_acc: 0.7615\n",
      "Epoch 71/100\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.8035 - acc: 0.7176 - val_loss: 0.6810 - val_acc: 0.7612\n",
      "Epoch 72/100\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.8011 - acc: 0.7208 - val_loss: 0.6769 - val_acc: 0.7657\n",
      "Epoch 73/100\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.7950 - acc: 0.7208 - val_loss: 0.7094 - val_acc: 0.7544\n",
      "Epoch 74/100\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.7895 - acc: 0.7225 - val_loss: 0.6929 - val_acc: 0.7625\n",
      "Epoch 75/100\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7905 - acc: 0.7238 - val_loss: 0.6766 - val_acc: 0.7654\n",
      "Epoch 76/100\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7834 - acc: 0.7251 - val_loss: 0.6767 - val_acc: 0.7644\n",
      "Epoch 77/100\n",
      "196/196 [==============================] - 10s 52ms/step - loss: 0.7802 - acc: 0.7255 - val_loss: 0.6786 - val_acc: 0.7627\n",
      "Epoch 78/100\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7781 - acc: 0.7265 - val_loss: 0.6667 - val_acc: 0.7690\n",
      "Epoch 79/100\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.7751 - acc: 0.7275 - val_loss: 0.6936 - val_acc: 0.7586\n",
      "Epoch 80/100\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.7693 - acc: 0.7291 - val_loss: 0.6664 - val_acc: 0.7692\n",
      "Epoch 81/100\n",
      "196/196 [==============================] - 11s 55ms/step - loss: 0.7699 - acc: 0.7299 - val_loss: 0.6674 - val_acc: 0.7681\n",
      "Epoch 82/100\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.7653 - acc: 0.7311 - val_loss: 0.6502 - val_acc: 0.7735\n",
      "Epoch 83/100\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7615 - acc: 0.7322 - val_loss: 0.6584 - val_acc: 0.7721\n",
      "Epoch 84/100\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7569 - acc: 0.7361 - val_loss: 0.6372 - val_acc: 0.7800\n",
      "Epoch 85/100\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7514 - acc: 0.7389 - val_loss: 0.6476 - val_acc: 0.7773\n",
      "Epoch 86/100\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7458 - acc: 0.7407 - val_loss: 0.6332 - val_acc: 0.7809\n",
      "Epoch 87/100\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.7451 - acc: 0.7385 - val_loss: 0.6346 - val_acc: 0.7800\n",
      "Epoch 88/100\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.7448 - acc: 0.7392 - val_loss: 0.6294 - val_acc: 0.7828\n",
      "Epoch 89/100\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.7367 - acc: 0.7426 - val_loss: 0.6311 - val_acc: 0.7810\n",
      "Epoch 90/100\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.7382 - acc: 0.7423 - val_loss: 0.6292 - val_acc: 0.7819\n",
      "Epoch 91/100\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.7323 - acc: 0.7451 - val_loss: 0.6575 - val_acc: 0.7749\n",
      "Epoch 92/100\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7245 - acc: 0.7449 - val_loss: 0.6242 - val_acc: 0.7850\n",
      "Epoch 93/100\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7239 - acc: 0.7435 - val_loss: 0.6356 - val_acc: 0.7810\n",
      "Epoch 94/100\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7249 - acc: 0.7458 - val_loss: 0.6185 - val_acc: 0.7871\n",
      "Epoch 95/100\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.7195 - acc: 0.7474 - val_loss: 0.6253 - val_acc: 0.7815\n",
      "Epoch 96/100\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.7178 - acc: 0.7494 - val_loss: 0.6325 - val_acc: 0.7819\n",
      "Epoch 97/100\n",
      "196/196 [==============================] - 11s 55ms/step - loss: 0.7124 - acc: 0.7508 - val_loss: 0.6091 - val_acc: 0.7904\n",
      "Epoch 98/100\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.7117 - acc: 0.7518 - val_loss: 0.6179 - val_acc: 0.7875\n",
      "Epoch 99/100\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.7097 - acc: 0.7513 - val_loss: 0.5929 - val_acc: 0.7950\n",
      "Epoch 100/100\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.7061 - acc: 0.7518 - val_loss: 0.5986 - val_acc: 0.7931\n",
      "Saved trained model at D:\\Spring 2018\\AI\\Assignment-1\\saved_models\\keras_cifar10_trained_model.h5 \n",
      "10000/10000 [==============================] - 1s 139us/step\n",
      "Test loss: 0.5986444727897644\n",
      "Test accuracy: 0.7931\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import configparser\n",
    "import os\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"/Spring 2018/AI/Assignment-1/configuration-3.ini\")\n",
    "\n",
    "batch_size = int(config.get('Constants','batch_size'))\n",
    "num_classes = int(config.get('Constants','num_classes'))\n",
    "epochs = int(config.get('Constants','epochs'))\n",
    "data_augmentation = config.get('Constants','data_augmentation')\n",
    "num_predictions = int(config.get('Constants','num_predictions'))\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "\n",
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By far, the best model is the one with configuration-2.ini."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
